{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7gLol3W438D"
      },
      "source": [
        "# PROJECT UNDERSTANDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDkcOmKD84pe"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "Sepsis is a life-threatening medical condition that occurs when the body's response to an infection injures its own tissues and organs. It is a leading cause of death in hospitals worldwide, and its incidence is increasing. Early diagnosis and treatment of sepsis are crucial for improving patient outcomes. However, sepsis can be difficult to diagnose in its early stages, as its symptoms can be subtle and nonspecific.\n",
        "\n",
        "Early diagnosis and treatment of sepsis is critical for improving patient outcomes. However, sepsis can be difficult to diagnose early because its symptoms are often non-specific and can overlap with other conditions. As a result, sepsis is often underdiagnosed or misdiagnosed, leading to delayed treatment and worse patient outcomes.\n",
        "\n",
        "A sepsis prediction model could help to improve the early diagnosis and treatment of sepsis by identifying patients who are at high risk of developing the condition. This could be done by using machine learning algorithms to analyze patient data from electronic health records (EHRs).\n",
        "\n",
        "\n",
        "\n",
        "Read About Data Columns **[here](https://github.com/fantastic-rambo/Embedding-Machine-Learning-Model-in-FastAPI/blob/main/data/README.md)**\n",
        "\n",
        "**About the Datasets:**\n",
        "\n",
        "* **ID:**                            Unique patient identifier.\n",
        "* **PRG** (Plasma glucose):          Measurement of plasma glucose levels.\n",
        "* **PL** (Blood Work Result-1):      First blood work result (in mu U/ml).\n",
        "* **PR** (Blood Pressure):           Blood pressure measurement (in mm Hg).\n",
        "* **SK** (Blood Work Result-2):       Second blood work result (in mm).\n",
        "* **TS** (Blood Work Result-3):       Third blood work result (in mu U/ml).\n",
        "* **M11** (Body mass index):          Body mass index calculated as weight in kg divided by the square of height in meters.\n",
        "* **BD2** (Blood Work Result-4):      Fourth blood work result (in mu U/ml).\n",
        "* **Age**: Age of the patient in years.\n",
        "\n",
        "* **Insurance**:              Binary indicator of whether the patient holds a valid insurance card.\n",
        "\n",
        "* **Sepsis**: Binary outcome indicating the development of sepsis in the ICU (Positive or Negative). otherwise\n",
        "\n",
        "\n",
        "## Goal Of Project\n",
        "The goal of the project is to develop a model that can predict whether or not a patient in the ICU will develop sepsis. This model could be used to identify patients who are at high risk of developing sepsis, allowing clinicians to initiate early treatment and improve patient outcomes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Hypothesis\n",
        "**Null Hypothesis (H0)**\n",
        "\n",
        "Age does not determine whether a patient will develop Sepsis.\n",
        "\n",
        "\n",
        "**Alternative Hypothesis (Ha)**\n",
        "\n",
        "Age determines whether a patient will develop Sepsis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Analytical Questions\n",
        "\n",
        "* What is the average age of those developing sepsis?\n",
        "\n",
        "* what is the Average BMI of those developing sepsis?\n",
        "\n",
        "* Are there discernible demographic patterns among patients who develop sepsis, such as age, insurance status, or other demographic variables?\n",
        "\n",
        "* What is the correlation between different medical indicators (e.g., plasma glucose, blood pressure) and the likelihood of developing sepsis?\n",
        "\n",
        "* Do specific blood work results exhibit a noticeable impact on the probability of sepsis development?\n",
        "\n",
        "* Is there a significant association between insurance status and the risk of developing sepsis in ICU patients?\n",
        "\n",
        "* How well can we predict the likelihood of sepsis based on the available variables in the dataset?\n",
        "\n",
        "* Are there any temporal trends in the occurrence of sepsis or changes in the distribution of key variables over time?\n",
        "\n",
        "* How do different predictive models perform in estimating the likelihood of sepsis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ARzXz6f74FW"
      },
      "source": [
        "# DATA UNDERSTANDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rvgb2Xab07PI"
      },
      "outputs": [],
      "source": [
        "# Installations\n",
        "!pip install -U imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-hT33WF2ENo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                       # For data manipulation and analysis\n",
        "import numpy as np                        # For numerical operations\n",
        "import matplotlib.pyplot as plt           # For data visualization\n",
        "import seaborn as sns                     # For statistical data visualization\n",
        "import re\n",
        "import threadpoolctl\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#import warning\n",
        "\n",
        "\n",
        "#Libraries for feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Libraries for Validation\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics   #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "#Libraries for Training model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import tree\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr-C0oilQKqX"
      },
      "outputs": [],
      "source": [
        "#Check numpy and pandas version\n",
        "\n",
        "print(\"Numpy version: \", np.__version__)\n",
        "print(\"Pandas version: \",pd.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoK7euYY3SmC"
      },
      "outputs": [],
      "source": [
        "#loading data from Github\n",
        "\n",
        "train_data = pd.read_csv(\"https://raw.githubusercontent.com/fantastic-rambo/Embedding-Machine-Learning-Model-in-FastAPI/main/data/Paitients_Files_Train.csv\")\n",
        "test_data = pd.read_csv(\"https://raw.githubusercontent.com/fantastic-rambo/Embedding-Machine-Learning-Model-in-FastAPI/main/data/Paitients_Files_Test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmT3vJ-E8L05"
      },
      "source": [
        "## **Data Understanding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRn1r1iQXReV"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3QvyOHYXWtf"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO08rvx9W7mu"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL3ccJg18QrP"
      },
      "outputs": [],
      "source": [
        "def display_dataset_info(train_data, test_data):\n",
        "    \"\"\"\n",
        "    Display information about the train and test datasets.\n",
        "\n",
        "    Parameters:\n",
        "    - train_df: DataFrame, the training dataset.\n",
        "    - test_df: DataFrame, the testing dataset.\n",
        "    \"\"\"\n",
        "    print(\"Train Dataset Info:\")\n",
        "    train_data.info()\n",
        "\n",
        "    print(\"\\nTest Dataset Info:\")\n",
        "    test_data.info()\n",
        "\n",
        "# Assuming you have train_data and test_data DataFrames\n",
        "display_dataset_info(train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w09YYrYGcMLd"
      },
      "outputs": [],
      "source": [
        "train_data.shape, test_data.shape          # checking for the shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLhkDh_FYeYL"
      },
      "source": [
        "From the training dataset, I extracted information revealing a total of 599 patient records, all complete with no missing values. The dataset comprises 11 columns, including the target variable 'Sepsis.'\n",
        "\n",
        "Also, From the test dataset, it is observed that there are a total of 169 entries. The dataset spans 10 columns, and it is noteworthy that the 'sepsis' target column is not present, indicating that sepsis outcome labels are not included in the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzOnsLlkXnla"
      },
      "outputs": [],
      "source": [
        "train_data.duplicated().sum(), test_data.duplicated().sum()   #checking for duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuF7pe6hbeBn"
      },
      "source": [
        "From The Above codes, (0, 0) depicts that both the Train and Test datasets do not possess duplicated rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imdhNJGsdRwB"
      },
      "outputs": [],
      "source": [
        "train_data.isna().sum()     #checking for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pp_Oy33dita"
      },
      "outputs": [],
      "source": [
        "test_data.isna().sum()    #checking for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPMROOTXcf02"
      },
      "outputs": [],
      "source": [
        "# Drop duplicates from the training dataset\n",
        "train_data = train_data.drop_duplicates()\n",
        "\n",
        "# Drop duplicates from the test dataset\n",
        "test_data = test_data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZlPtDijYEW8"
      },
      "outputs": [],
      "source": [
        "train_data.describe()     #checking statistical info of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPIwlqA6dF_s"
      },
      "outputs": [],
      "source": [
        "test_data.describe()       #checking statistical info of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjmASh-lge6f"
      },
      "outputs": [],
      "source": [
        "# a heatmap of missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(train_data.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Missing Values in Each Column')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv2-B1YeEBm3"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='Sepssis',y='Age', data=train_data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2zsn7kcWv6R"
      },
      "outputs": [],
      "source": [
        "# plot the boxplot to see the outlier of each numerical column\n",
        "sns.boxplot(data=train_data,orient=\"v\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3T5U4KTXbVw"
      },
      "outputs": [],
      "source": [
        "# Pie chart\n",
        "labels = ['Sepsis', 'Not Sepsis']\n",
        "#colors\n",
        "colors = ['#94B3FD', '#F9C5D5']\n",
        "ax = plt.pie(train_data['Sepssis'].value_counts(), labeldistance=1.15,\n",
        "labels=labels, colors=colors, autopct='%1.1f%%',\n",
        "textprops={'fontsize': 16});\n",
        "plt.title('Proportion of Sepsis', fontsize=25, fontweight = 'bold')\n",
        "plt.rcParams['figure.figsize'] = [10, 7]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFmyh8Lub15D"
      },
      "outputs": [],
      "source": [
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Univariate Analysis: Distribution of Patient Ages\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(train_data['Age'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Patient Ages')\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Univariate Analysis: Box Plot for Plasma Glucose Levels\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=train_data['PRG'], color='lightcoral')\n",
        "plt.title('Box Plot of Plasma Glucose Levels')\n",
        "plt.xlabel('Plasma Glucose Level (Attribute1)')\n",
        "plt.show()\n",
        "\n",
        "# Univariate Analysis: Bar Chart for Insurance Status\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=train_data['Insurance'], palette='pastel')\n",
        "plt.title('Insurance Status Distribution')\n",
        "plt.xlabel('Insurance Status')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZH5IELkb9CN"
      },
      "outputs": [],
      "source": [
        "# Bivariate Analysis: Scatter Plot of Plasma Glucose Levels and Blood Pressure\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=train_data['PRG'], y=train_data['PR'], color='skyblue')\n",
        "plt.title('Scatter Plot of Plasma Glucose Levels vs. Blood Pressure')\n",
        "plt.xlabel('Plasma Glucose Level (Attribute1)')\n",
        "plt.ylabel('Blood Pressure (Attribute3)')\n",
        "plt.show()\n",
        "\n",
        "# Bivariate Analysis: Box Plot of Plasma Glucose Levels Grouped by Insurance Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=train_data['Insurance'], y=train_data['PRG'], palette='pastel')\n",
        "plt.title('Box Plot of Plasma Glucose Levels Grouped by Insurance Status')\n",
        "plt.xlabel('Insurance Status')\n",
        "plt.ylabel('Plasma Glucose Level (Attribute1)')\n",
        "plt.show()\n",
        "\n",
        "# Bivariate Analysis: Violin Plot of Body Mass Index and Blood Work Result-2\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x=train_data['M11'], y=train_data['SK'], palette='muted')\n",
        "plt.title('Violin Plot of Body Mass Index vs. Blood Work Result-2')\n",
        "plt.xlabel('Body Mass Index (Attribute6)')\n",
        "plt.ylabel('Blood Work Result-2 (Attribute4)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8jSTclpZpqy"
      },
      "outputs": [],
      "source": [
        "# Selecting four numerical columns for the pair plot\n",
        "selected_numerical_columns = ['PRG', 'PL', 'PR', 'M11']\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Multivariate Analysis: Pair Plot for Selected Numerical Columns\n",
        "sns.pairplot(train_data[selected_numerical_columns])\n",
        "plt.suptitle('Pair Plot for Selected Numerical Columns', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN-Hnqn-dud3"
      },
      "outputs": [],
      "source": [
        "# Selecting all numerical columns for the correlation heatmap\n",
        "numerical_columns = train_data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numerical_columns.corr()\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Create a heatmap for the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap for Numerical Columns')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-Bei0qQsVyX"
      },
      "outputs": [],
      "source": [
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot box plots for each numerical column\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.boxplot(data=train_data, orient='h', palette='Set2')\n",
        "plt.title('Box Plots for Numerical Columns to Identify Outliers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCsnMdIYujmM"
      },
      "outputs": [],
      "source": [
        "# Print column names\n",
        "print(train_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiAxM6EqswMN"
      },
      "outputs": [],
      "source": [
        "# Specify the columns of interest\n",
        "columns_of_interest =  ['PRG', 'PL', 'PR', 'SK', 'TS', 'M11', 'BD2', 'Age', 'Insurance']\n",
        "\n",
        "# Check if outliers still exist in the columns\n",
        "outliers_exist = False\n",
        "\n",
        "for column in columns_of_interest:\n",
        "    # Calculate the first and third quartiles (Q1 and Q3)\n",
        "    Q1 = train_data[column].quantile(0.25)\n",
        "    Q3 = train_data[column].quantile(0.75)\n",
        "\n",
        "    # Calculate the interquartile range (IQR)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define the lower and upper bounds for outliers\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Modify the values in the column to be within the range\n",
        "    train_data[column] = train_data[column].clip(lower_bound, upper_bound)\n",
        "\n",
        "    # Check if outliers exist in the column\n",
        "    if (train_data[column] < lower_bound).any() or (train_data[column] > upper_bound).any():\n",
        "        outliers_exist = True\n",
        "        print(f\"Outliers still exist in '{column}'.\")\n",
        "\n",
        "if not outliers_exist:\n",
        "    print(\"No outliers exist in the specified columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCacUmDpxJxY"
      },
      "outputs": [],
      "source": [
        "#checking again for outliers after removing them\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot box plots for each numerical column\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.boxplot(data=train_data, orient='h', palette='Set2')\n",
        "plt.title('Box Plots for Numerical Columns to Identify Outliers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZDXrx69DuT0"
      },
      "source": [
        "### Issues With the Data\n",
        "* The column names are not very descriptive.\n",
        "\n",
        "* The target variable 'Sepssis' may have imbalanced classes.\n",
        "\n",
        "* There are many outliers in some of the numerical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RY73CBZjq9U"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Assuming 'Age' is the column representing patient age\n",
        "age_sepsis_positive = train_data[train_data['Sepssis'] == 'Positive']['Age']\n",
        "age_sepsis_negative = train_data[train_data['Sepssis'] == 'Negative']['Age']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(age_sepsis_positive, age_sepsis_negative, equal_var=False)\n",
        "\n",
        "# Print results\n",
        "print(f'T-statistic: {t_stat}')\n",
        "print(f'P-value: {p_value}')\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in average age.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in average age.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWwqBycjeC4e"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv6oB1zbcJYv"
      },
      "outputs": [],
      "source": [
        "# Rename the columns\n",
        "train_data = train_data.rename(columns={\n",
        "    \"PRG\": \"Plasma_glucose\",\n",
        "    \"PL\": \"Blood_Work_R1\",\n",
        "    \"PR\": \"Blood_Pressure\",\n",
        "    \"SK\": \"Blood_Work_R2\",\n",
        "    \"TS\": \"Blood_Work_R3\",\n",
        "    \"M11\": \"BMI\",\n",
        "    \"BD2\": \"Blood_Work_R4\",\n",
        "    \"Age\": \"Patient_age\",\n",
        "    \"Sepssis\": \"Sepsis\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYf55H3UjFDC"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBWCKBNrm-JD"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(train_data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTTTc0xCnIyW"
      },
      "outputs": [],
      "source": [
        "# Replace \"Positive\" with 1 and \"Negative\" with 0\n",
        "train_data['Sepsis'] = train_data['Sepsis'].replace({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "# Print the updated DataFrame\n",
        "train_data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka8uLRKGl3Iw"
      },
      "source": [
        "## **Dropping Unnecessary Columns**\n",
        "* We will remove Blood_work_R2\n",
        "\n",
        "* We will remove the ID column\n",
        "\n",
        "* we drop Insurance as well since it isnt a relevant field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkbzaGr1lu9y"
      },
      "outputs": [],
      "source": [
        "#dropping unnecessary columns\n",
        "\n",
        "train_data = train_data.drop(['Blood_Work_R2', 'ID', 'Insurance'], axis=1)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJBABUn9VCm6"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5boWyBKapBTG"
      },
      "source": [
        "## **Data Spliting**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7_835wCpRcE"
      },
      "outputs": [],
      "source": [
        "#Splitting data into x_train and x_test\n",
        "\n",
        "X = train_data.drop('Sepsis', axis=1)\n",
        "y = train_data['Sepsis']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#checking shape after splitting\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzhqhpAZrjTb"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOl5nqz1rswT"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NNOoau0x28r"
      },
      "source": [
        "## **Detecting Data Imbalance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doWvMvikyB8s"
      },
      "outputs": [],
      "source": [
        "# Count and plot the distribution of the original 'Sepsis' classes\n",
        "sns.countplot(x=y_train, palette='Set2')\n",
        "plt.title('Original Distribution of Sepsis Classes')\n",
        "plt.show()\n",
        "\n",
        "# Check the distribution of values in the 'Sepsis' column\n",
        "sepsis_distribution = y_train.value_counts()\n",
        "\n",
        "# Print the distribution\n",
        "print(sepsis_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-OYjWZAziJL"
      },
      "source": [
        "Dataset is imbalanced so we can't use Accuracy Score to choose our model\n",
        "\n",
        "To solve this issue: we'll Oversample our minority class using RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb8WDnDT1Eka"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Count and plot the distribution of the resampled 'Sepsis' classes\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=y_resampled, palette='Set2')\n",
        "plt.title('Resampled Distribution of Sepsis Classes using SMOTE')\n",
        "plt.show()\n",
        "\n",
        "# Check the distribution of values in the 'Sepsis' column\n",
        "sepsis_distribution = y_resampled.value_counts()\n",
        "\n",
        "# Print the distribution\n",
        "print(sepsis_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG4IHKfO382w"
      },
      "source": [
        "## **Feature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4KwIhHf4R6l"
      },
      "outputs": [],
      "source": [
        "# Create an instance of StandardScaler and set output to be a DataFrame\n",
        "scaler = StandardScaler().fit(X_train).set_output (transform=\"pandas\")\n",
        "\n",
        "# Scale the training data\n",
        "X_train_df = scaler.transform(X_train)\n",
        "\n",
        "# Scale the test data using the same scaler\n",
        "X_test_df = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGaosD8Ft-SR"
      },
      "source": [
        "## **Save Preprocessed Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSmOVaRWuECt"
      },
      "outputs": [],
      "source": [
        "# # Save the preprocessed data to a new CSV file\n",
        "# X_train_df.to_csv('preprocessed_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA61R-bp8tBZ"
      },
      "source": [
        "# MODELLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nfTdJFLu3FJ"
      },
      "source": [
        "Here is the section to build, train, evaluate and compare the models to each other.\n",
        "* Logistic Regression\n",
        "* RandomForest Classifier\n",
        "* XGBoost Classifier\n",
        "* K Nearest Neighbors\n",
        "* Support Vector Machines\n",
        "* DecisionTreeClassifier\n",
        "* Gradient Boosting Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6GFGF8j8w8V"
      },
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'K Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machines': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1V5Uke2c4eV"
      },
      "outputs": [],
      "source": [
        "models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy76MzWQ8x5W"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "180NzDHAgSh_"
      },
      "outputs": [],
      "source": [
        "# Initialize DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='binary')  # Add 'average' parameter\n",
        "    recall = recall_score(y_test, y_pred, average='binary')  # Add 'average' parameter\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')  # Add 'average' parameter\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Add results to DataFrame\n",
        "    results_df = results_df.append({'Model': name, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1, 'ROC AUC': roc_auc}, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCw52CshZgKM"
      },
      "outputs": [],
      "source": [
        "# Display the results DataFrame\n",
        "print(\"\\nResults Summary:\")\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1stTus0cVta"
      },
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr5N3cmaiEKm"
      },
      "source": [
        "## Models Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zGUFYgWg1nT"
      },
      "outputs": [],
      "source": [
        "# Set the style for seaborn\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Plot the accuracy of each model using seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Model', y='Accuracy', data=results_df, color='green')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy of Each Model')\n",
        "plt.ylim(0, 1)  # Set y-axis limit between 0 and 1 for accuracy\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE6zgubDvjOh"
      },
      "source": [
        "## **k-Fold Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ETRITjdrult"
      },
      "outputs": [],
      "source": [
        "def kfold_cross_validation(model, X, y, num_folds=5):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross-validation for a given model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Machine learning model.\n",
        "    - X: Features.\n",
        "    - y: Target variable.\n",
        "    - num_folds: Number of folds for cross-validation.\n",
        "\n",
        "    Returns:\n",
        "    - results_df: DataFrame containing cross-validation results.\n",
        "    \"\"\"\n",
        "    # Initialize StratifiedKFold\n",
        "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # Initialize DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=['Fold', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'])\n",
        "\n",
        "    # Iterate over folds\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Fit the model on the training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "        # Append results to the DataFrame\n",
        "        results_df = results_df.append({\n",
        "            'Fold': fold + 1,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1,\n",
        "            'ROC AUC': roc_auc\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faeFjwM1nakS"
      },
      "outputs": [],
      "source": [
        "# def kfold_cross_validation_for_models(models, X, y, num_folds=5):\n",
        "#     \"\"\"\n",
        "#     Perform k-fold cross-validation for each model.\n",
        "\n",
        "#     Parameters:\n",
        "#     - models: Dictionary of models to evaluate.\n",
        "#     - X: Features.\n",
        "#     - y: Target variable.\n",
        "#     - num_folds: Number of folds for cross-validation.\n",
        "\n",
        "#     Returns:\n",
        "#     - results_df: DataFrame containing cross-validation results for each model.\n",
        "#     \"\"\"\n",
        "#     # Initialize DataFrame to store results\n",
        "#     results_df = pd.DataFrame(columns=['Model', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'])\n",
        "\n",
        "#     # Iterate over models\n",
        "#     for model_name, model in models.items():\n",
        "#         print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "#         # Perform k-fold cross-validation for the current model\n",
        "#         cv_results = kfold_cross_validation(model, X, y, num_folds=num_folds)\n",
        "\n",
        "#         # Add model name to the results\n",
        "#         cv_results['Model'] = model_name\n",
        "\n",
        "#         # Append results to the main DataFrame\n",
        "#         results_df = results_df.append(cv_results, ignore_index=True)\n",
        "\n",
        "#     return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3NGGKHJToPV"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "# Replace RandomForestClassifier() and XGBClassifier() with your desired models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'K Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machines': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "cv_results_all_models = kfold_cross_validation_for_models(models, X, y, num_folds=5)\n",
        "\n",
        "# Display the cross-validation results DataFrame for all models\n",
        "print(\"\\nCross-Validation Results for All Models:\")\n",
        "cv_results_all_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FmCO4Shq8bQ"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame to include only the accuracy results\n",
        "accuracy_results_all_models = cv_results_all_models[['Model', 'Accuracy']]\n",
        "\n",
        "# Plot the bar chart\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Model', y='Accuracy', data=accuracy_results_all_models, palette='viridis')\n",
        "plt.title('Model Comparison - 5-Fold Cross-Validation Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)  # Set the y-axis limit to the range of accuracy (0 to 1)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaGz6Hhhum2O"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame to include only the accuracy results for the 5th fold\n",
        "accuracy_results_5th_fold = cv_results_all_models[cv_results_all_models['Fold'] == 5][['Model', 'Accuracy']]\n",
        "\n",
        "# Print the accuracy for the 5th fold for each model\n",
        "print(\"\\nAccuracy for the 5th Fold:\")\n",
        "accuracy_results_5th_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zfMXVmIwMJd"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean accuracy for each model\n",
        "mean_accuracy_by_model = cv_results_all_models.groupby('Model')['Accuracy'].mean()\n",
        "\n",
        "# Select the top two models with the highest mean accuracy\n",
        "top_two_models = mean_accuracy_by_model.nlargest(2)\n",
        "\n",
        "# Print the two best models and their mean accuracies\n",
        "print(\"\\nTwo Best Models based on k-fold Cross-Validation:\\n\")\n",
        "for model, mean_accuracy in top_two_models.items():\n",
        "    print(f\"Model: {model}, Mean Accuracy: {mean_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWw7q70Ovv0O"
      },
      "source": [
        "# **Hyperparameters Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QlST9DOv3m3"
      },
      "outputs": [],
      "source": [
        "# # Create a pipeline with a model (RandomForestClassifier)\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "# # Define the hyperparameter grid to search\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'min_samples_split': [2, 6, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4]\n",
        "# }\n",
        "\n",
        "# # Create the GridSearchCV object\n",
        "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Print the best hyperparameters and corresponding accuracy\n",
        "# print(\"Best Hyperparameters:\")\n",
        "# print(grid_search.best_params_)\n",
        "# print(\"Best Accuracy on Training Data:\", grid_search.best_score_)\n",
        "\n",
        "# # Evaluate the best model on the test set\n",
        "# best_model = grid_search.best_estimator_\n",
        "# test_accuracy = best_model.score(X_test, y_test)\n",
        "# print(\"Accuracy on Test Data:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create hyperparameter grids for each model\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV objects for each model\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the grid searches to the data\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding accuracy for each model\n",
        "print(\"Best Hyperparameters for RandomForestClassifier:\")\n",
        "print(grid_search_rf.best_params_)\n",
        "print(\"Best Accuracy on Training Data:\", grid_search_rf.best_score_)\n",
        "\n",
        "print(\"\\nBest Hyperparameters for LogisticRegression:\")\n",
        "print(grid_search_lr.best_params_)\n",
        "print(\"Best Accuracy on Training Data:\", grid_search_lr.best_score_)\n",
        "\n",
        "# Evaluate the best models on the test set\n",
        "best_model_rf = grid_search_rf.best_estimator_\n",
        "test_accuracy_rf = best_model_rf.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on Test Data (RandomForestClassifier):\", test_accuracy_rf)\n",
        "\n",
        "best_model_lr = grid_search_lr.best_estimator_\n",
        "test_accuracy_lr = best_model_lr.score(X_test, y_test)\n",
        "print(\"Accuracy on Test Data (LogisticRegression):\", test_accuracy_lr)"
      ],
      "metadata": {
        "id": "jB4ZMOMDj_nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exporting Model and Preprocessor**"
      ],
      "metadata": {
        "id": "ZyiM3XCastRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(best_model_rf, 'best_model_rf.joblib')\n",
        "\n",
        "# Save the preprocessor\n",
        "joblib.dump(scaler, 'scaler.joblib')"
      ],
      "metadata": {
        "id": "iFEyc3jDs5rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get requirements\n",
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "y8OvlBOe3JTa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}